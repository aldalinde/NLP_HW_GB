{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ –∫ —É—Ä–æ–∫—É 8. \n",
    "–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ RNN LSTM GRU\n",
    "–î–∞–Ω–Ω—ã–µ –±–µ—Ä–µ–º –æ—Ç—ã–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ\n",
    "\n",
    "–ù–∞ –≤–µ–±–∏–Ω–∞—Ä–µ –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏, —á—Ç–æ –¥–æ–ª–≥–æ–µ –≤—Ä–µ–º—è CNN –∏ RNN –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –±—ã–ª–∏ –∫–æ–Ω—É—Ä–∏—Ä—É–µ—â–∏–º–∏ –≤—ã—è—Å–Ω–∏—Ç—å –∫–∞–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–æ–ª—å—à–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏\n",
    "\n",
    "–ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã\n",
    "\n",
    "–ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å RNN\n",
    "\n",
    "–ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–æ–≤–º–µ—Å—Ç–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã CNN -> RNN –∏–ª–∏ (RNN -> CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø–æ–ø—Ä–æ–±—É–µ–º –∑–∞–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—É—é —Ä–µ–∫—É—Ä–µ–Ω—Ç–Ω—É—é —Å–µ—Ç—å. –í–æ–∑—å–º–µ–º –¥–∞—Ç–∞—Å–µ—Ç —Å –ø—Ä–æ—à–ª–æ–≥–æ –∑–∞–Ω—è—Ç–∏—è\n",
    "\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/Otzyvy.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20659 entries, 0 to 20658\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Rating   20659 non-null  int64 \n",
      " 1   Content  20656 non-null  object\n",
      " 2   Date     20659 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 484.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\s–Ω–µ\", \"–Ω–µ\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Flatten, Reshape\n",
    "from keras.layers import Conv1D, GlobalMaxPool1D, MaxPooling1D, SimpleRNN, LSTM, GRU, Masking\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['Content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>it just works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>—Ü–µ–ª–æ–µ —É–¥–æ–±–Ω–æ–Ω–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–∏–∑ –º–∏–Ω—É—Å —Ö–æ—Ç–µ—Ç—å –±–æ–ª—å...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>–æ—Ç–ª–∏—á–Ω–æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>–∑–∞–≤–∏—Å–∞—Ç—å 1 —Ä–∞–±–æ—Ç–∞ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å —Ä–∞–Ω–µ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>—É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±—ã—Å—Ç—Ä–æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>—É–¥–æ–±–Ω–æ –Ω–æ—Ä–º–∞ üëçüëçüëç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>—É–¥–æ–±–Ω—ã–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>—É—Å—Ç—Ä–∞–∏–≤–∞—Ç—å</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>–£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>—Ä–∞–±–æ—Ç–∞—Ç—å —á—ë—Ç–∫–æ –æ—Ç–ª–∏—á–∏–µ –±–∞–Ω–∫–æ–º–∞—Ç –≤–µ—á–Ω–æ –∑–∞–≤–∏—Å–∞—Ç—å...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>—Ö–æ—Ä–æ—à–æüëç</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date   \n",
       "0       5                                     It just works!  2017-08-14  \\\n",
       "1       4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14   \n",
       "2       5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14   \n",
       "3       5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14   \n",
       "4       5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14   \n",
       "5       5                                –í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç  2017-08-14   \n",
       "6       5                          –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.  2017-08-14   \n",
       "7       5                                     –í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç  2017-08-14   \n",
       "8       5  –£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...  2017-08-14   \n",
       "9       5                                  –û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç  2017-08-14   \n",
       "\n",
       "                                           processed  \n",
       "0                                      it just works  \n",
       "1  —Ü–µ–ª–æ–µ —É–¥–æ–±–Ω–æ–Ω–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–∏–∑ –º–∏–Ω—É—Å —Ö–æ—Ç–µ—Ç—å –±–æ–ª—å...  \n",
       "2                                            –æ—Ç–ª–∏—á–Ω–æ  \n",
       "3  –∑–∞–≤–∏—Å–∞—Ç—å 1 —Ä–∞–±–æ—Ç–∞ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å —Ä–∞–Ω–µ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è...  \n",
       "4                             —É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±—ã—Å—Ç—Ä–æ  \n",
       "5                                   —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º–∞ üëçüëçüëç  \n",
       "6                                 —É–¥–æ–±–Ω—ã–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ  \n",
       "7                                         —É—Å—Ç—Ä–∞–∏–≤–∞—Ç—å  \n",
       "8  —Ä–∞–±–æ—Ç–∞—Ç—å —á—ë—Ç–∫–æ –æ—Ç–ª–∏—á–∏–µ –±–∞–Ω–∫–æ–º–∞—Ç –≤–µ—á–Ω–æ –∑–∞–≤–∏—Å–∞—Ç—å...  \n",
       "9                                            —Ö–æ—Ä–æ—à–æüëç  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "5    14586\n",
       "1     2276\n",
       "4     2138\n",
       "3      911\n",
       "2      748\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**adjustment after several tries**   \n",
    "- *Epochs =5 with early_stopping. With less epochs accuracy on validation (built-in model validation of 10%) after 3rd to 10 epochs begins to drop, while on train corpus loss continues to fall and accuracy to rise which seemes to indicate overlearning, BUT on test lower total accuracy gives all classes (even minor) prediction better, whereas if we stop at the lowest loss on validation, we get only three biggest classes TRUE-predictions at all*   \n",
    "- *training length from max size of the tweet 132 -> 99.45 percentile length 39 +1*\n",
    "- *with batch size 512 less sophisticated models overperformed on class 5 and ignored all other classes/ GRU, LSTM and longerRNN have done better, but still worse than with batch size 100. Batch size 100 worked out more stable for all models being able to distinguish classes 5, 4, 1. We'l stop with batch 64*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "batch_size = 64\n",
    "epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['processed'], df['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus_train = x_train.values\n",
    "text_corpus_test = x_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(i.split()) for i in text_corpus_train], 99.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.998838259971602"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(i.split()) for i in text_corpus_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, \n",
    "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, split = ' ')\n",
    "tokenizer.fit_on_texts(text_corpus_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
    "\n",
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in text_corpus_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
    "X_test = pad_sequences(sequences_test, maxlen=training_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15494, 132)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=132,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categ = keras.utils.to_categorical(y_train-1, num_classes)\n",
    "y_test_categ = keras.utils.to_categorical(y_test-1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "218/218 [==============================] - 15s 62ms/step - loss: 0.8148 - categorical_accuracy: 0.7403 - val_loss: 0.6831 - val_categorical_accuracy: 0.7613\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 13s 62ms/step - loss: 0.6120 - categorical_accuracy: 0.7915 - val_loss: 0.6835 - val_categorical_accuracy: 0.7600\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train_categ,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 1s 16ms/step - loss: 0.6752 - categorical_accuracy: 0.7634\n",
      "\n",
      "\n",
      "Test score: [0.6752148866653442, 0.7634075284004211]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_categ, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "results_RNN = model.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_df(results, true_classes_values, index=None):\n",
    "    classes = [np.argmax(x)+1 for x in results]\n",
    "    if index is not None:\n",
    "        df_classes = pd.DataFrame({'true': true_classes_values, 'pred': classes},\n",
    "                                   index=index, columns=['true', 'pred'])\n",
    "    else:\n",
    "        df_classes = pd.DataFrame({'true': true_classes_values, 'pred': classes},\n",
    "                                   columns=['true', 'pred'])\n",
    "    df_classes['accuracy_tag'] = 0\n",
    "    df_classes.loc[df_classes['true']==df_classes['pred'], ['accuracy_tag']] = 1\n",
    "    \n",
    "    return df_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(df, class_name):\n",
    "    accuracy_tags = df.loc[(df['true']==class_name), ['accuracy_tag']].value_counts()\n",
    "    false_tags = df.loc[(df['true']==class_name), ['pred']].value_counts()\n",
    "    total = 0\n",
    "    if 1 in accuracy_tags.index:\n",
    "        if 0 in accuracy_tags.index:\n",
    "            total = accuracy_tags[1]+accuracy_tags[0]            \n",
    "            accuracy_percent = accuracy_tags[1] / total\n",
    "        else:\n",
    "            total = accuracy_tags[1]            \n",
    "            accuracy_percent = 100\n",
    "    else:\n",
    "        total = accuracy_tags[0]\n",
    "        accuracy_percent=0\n",
    "    \n",
    "    return false_tags, accuracy_percent, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_preds = get_classes_df(results_RNN, y_test.values, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n",
       "5    3647\n",
       "1     556\n",
       "4     534\n",
       "3     227\n",
       "2     201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_preds['true'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "5    10939\n",
       "1     1720\n",
       "4     1604\n",
       "3      684\n",
       "2      547\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 5 class is 0.9479023855223472 %\n",
      "Accuracy for 1 class is 0.7482014388489209 %\n",
      "Accuracy for 4 class is 0.12172284644194757 %\n",
      "Number of predicted class tags for 4 class in total 534: \n",
      " pred\n",
      "5       353\n",
      "1       105\n",
      "4        65\n",
      "3         6\n",
      "2         5\n",
      "Name: count, dtype: int64\n",
      "Accuracy for 3 class is 0.022026431718061675 %\n",
      "Number of predicted class tags for 3 class in total 227: \n",
      " pred\n",
      "1       124\n",
      "5        61\n",
      "4        32\n",
      "2         5\n",
      "3         5\n",
      "Name: count, dtype: int64\n",
      "Accuracy for 2 class is 0 %\n",
      "Number of predicted class tags for 2 class in total 201: \n",
      " pred\n",
      "1       138\n",
      "5        36\n",
      "4        23\n",
      "3         4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for class_name in df_test_preds['pred'].value_counts().index:\n",
    "    false_tags, g_a, total = get_accuracy(df_test_preds, class_name)\n",
    "    print(f'Accuracy for {class_name} class is {g_a} %')\n",
    "    if g_a <= 0.4:\n",
    "        print(f'Number of predicted class tags for {class_name} class in total {total}: \\n {false_tags}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*worse than CNN in hw7*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN+RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CRNN = Sequential()\n",
    "\n",
    "model_CRNN.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=64,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model_CRNN.add(Masking(mask_value=0.0))\n",
    "model_CRNN.add(Conv1D(128, 3))\n",
    "model_CRNN.add(Activation(\"relu\"))\n",
    "model_CRNN.add(GlobalMaxPool1D(data_format=\"channels_first\", keepdims=True))\n",
    "model_CRNN.add(SimpleRNN(64))\n",
    "model_CRNN.add(Dense(32, activation='relu'))\n",
    "model_CRNN.add(Dropout(0.5))\n",
    "model_CRNN.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_CRNN.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 132, 64)           710976    \n",
      "                                                                 \n",
      " masking_1 (Masking)         (None, 132, 64)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 130, 128)          24704     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 130, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 130, 1)           0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 64)                4224      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 742,149\n",
      "Trainable params: 742,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "218/218 [==============================] - 12s 47ms/step - loss: 0.8985 - categorical_accuracy: 0.7108 - val_loss: 0.7111 - val_categorical_accuracy: 0.7465\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 10s 47ms/step - loss: 0.7054 - categorical_accuracy: 0.7618 - val_loss: 0.6844 - val_categorical_accuracy: 0.7523\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 10s 46ms/step - loss: 0.6236 - categorical_accuracy: 0.7830 - val_loss: 0.6942 - val_categorical_accuracy: 0.7535\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model_CRNN.fit(X_train, y_train_categ,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 1s 15ms/step - loss: 0.6875 - categorical_accuracy: 0.7636\n",
      "\n",
      "\n",
      "Test score: [0.687508225440979, 0.7636011838912964]\n"
     ]
    }
   ],
   "source": [
    "score = model_CRNN.evaluate(X_test, y_test_categ, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "results_CRNN = model_CRNN.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CRNN_preds = get_classes_df(results_CRNN, y_test.values, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy_tag\n",
       "1               3479\n",
       "0                168\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CRNN_preds.loc[(df_CRNN_preds['true']==5), ['accuracy_tag']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 5 class is 0.9539347408829175 %\n",
      "Accuracy for 1 class is 0.8309352517985612 %\n",
      "Accuracy for 4 class is 0.0056179775280898875 %\n",
      "Number of predicted class tags for 4 class in total 534: \n",
      " pred\n",
      "5       381\n",
      "1       150\n",
      "4         3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for class_name in df_CRNN_preds['pred'].value_counts().index:\n",
    "    false_tags, g_a, total = get_accuracy(df_CRNN_preds, class_name)\n",
    "    print(f'Accuracy for {class_name} class is {g_a} %')\n",
    "    if g_a <= 0.4:\n",
    "        print(f'Number of predicted class tags for {class_name} class in total {total}: \\n {false_tags}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN+CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RCNN = Sequential()\n",
    "\n",
    "model_RCNN.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=64,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "#model_RCNN.add(Masking(mask_value=0.0))\n",
    "model_RCNN.add(SimpleRNN(128))\n",
    "model_RCNN.add(Reshape((128, 1), input_shape=(128,)))\n",
    "model_RCNN.add(Conv1D(128, 3))\n",
    "model_RCNN.add(Activation(\"relu\"))\n",
    "model_RCNN.add(GlobalMaxPool1D(data_format=\"channels_first\", keepdims=True))\n",
    "model_RCNN.add(Conv1D(80, 3))\n",
    "model_RCNN.add(Activation(\"relu\"))\n",
    "#model_RCNN.add(GlobalMaxPool1D(data_format=\"channels_first\", keepdims=True))\n",
    "model_RCNN.add(Conv1D(50, 3))\n",
    "model_RCNN.add(Activation(\"relu\"))\n",
    "model_RCNN.add(GlobalMaxPool1D())\n",
    "#model_RCNN.add(GlobalMaxPool1D(data_format=\"channels_first\", keepdims=True))\n",
    "model_RCNN.add(Dense(32, activation='relu'))\n",
    "model_RCNN.add(Dropout(0.5))\n",
    "model_RCNN.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_RCNN.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 132, 64)           710976    \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 128)               24704     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 128, 1)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 126, 128)          512       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 126, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 126, 1)           0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 124, 80)           320       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 124, 80)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 122, 50)           12050     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 122, 50)           0         \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 50)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1632      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 750,359\n",
      "Trainable params: 750,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_RCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "218/218 [==============================] - 22s 92ms/step - loss: 1.0140 - categorical_accuracy: 0.7030 - val_loss: 0.7950 - val_categorical_accuracy: 0.7032\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 20s 90ms/step - loss: 0.7669 - categorical_accuracy: 0.7155 - val_loss: 0.7560 - val_categorical_accuracy: 0.7181\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 20s 90ms/step - loss: 0.6755 - categorical_accuracy: 0.7524 - val_loss: 0.7559 - val_categorical_accuracy: 0.7084\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 19s 89ms/step - loss: 0.6271 - categorical_accuracy: 0.7715 - val_loss: 0.8054 - val_categorical_accuracy: 0.7013\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model_RCNN.fit(X_train, y_train_categ,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 2s 27ms/step - loss: 0.7858 - categorical_accuracy: 0.7336\n",
      "\n",
      "\n",
      "Test score: [0.7857568264007568, 0.7335914969444275]\n"
     ]
    }
   ],
   "source": [
    "score = model_RCNN.evaluate(X_test, y_test_categ, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 2s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "results_RCNN = model_RCNN.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RCNN_preds = get_classes_df(results_RCNN, y_test.values, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 5 class is 0.8947079791609542 %\n",
      "Accuracy for 1 class is 0.9226618705035972 %\n",
      "Accuracy for 4 class is 0.024344569288389514 %\n",
      "Number of predicted class tags for 4 class in total 534: \n",
      " pred\n",
      "5       278\n",
      "1       243\n",
      "4        13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for class_name in df_RCNN_preds['pred'].value_counts().index:\n",
    "    false_tags, g_a, total = get_accuracy(df_RCNN_preds, class_name)\n",
    "    print(f'Accuracy for {class_name} class is {g_a} %')\n",
    "    if g_a <= 0.4:\n",
    "        print(f'Number of predicted class tags for {class_name} class in total {total}: \\n {false_tags}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Longer RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_longRNN = Sequential()\n",
    "\n",
    "model_longRNN.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=128,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model_longRNN.add(Masking(mask_value=0.0))\n",
    "model_longRNN.add(SimpleRNN(128, return_sequences=True))\n",
    "model_longRNN.add(SimpleRNN(80))\n",
    "model_longRNN.add(Dense(64, activation='relu'))\n",
    "model_longRNN.add(Dense(32, activation='relu'))\n",
    "model_longRNN.add(Dropout(0.5))\n",
    "model_longRNN.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_longRNN.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "218/218 [==============================] - 32s 134ms/step - loss: 0.8559 - categorical_accuracy: 0.7185 - val_loss: 0.6957 - val_categorical_accuracy: 0.7503\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 29s 133ms/step - loss: 0.6739 - categorical_accuracy: 0.7704 - val_loss: 0.6850 - val_categorical_accuracy: 0.7542\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 29s 133ms/step - loss: 0.5560 - categorical_accuracy: 0.8110 - val_loss: 0.7235 - val_categorical_accuracy: 0.7394\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model_longRNN.fit(X_train, y_train_categ,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 3s 42ms/step - loss: 0.7242 - categorical_accuracy: 0.7518\n",
      "\n",
      "\n",
      "Test score: [0.7241938710212708, 0.7517908811569214]\n"
     ]
    }
   ],
   "source": [
    "score = model_longRNN.evaluate(X_test, y_test_categ, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 4s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "results_longRNN = model_longRNN.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_longRNN = get_classes_df(results_longRNN, y_test.values, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 5 class is 0.945160405812997 %\n",
      "Accuracy for 1 class is 0.6564748201438849 %\n",
      "Accuracy for 4 class is 0.10486891385767791 %\n",
      "Number of predicted class tags for 4 class in total 534: \n",
      " pred\n",
      "5       356\n",
      "1       103\n",
      "4        56\n",
      "2        11\n",
      "3         8\n",
      "Name: count, dtype: int64 \n",
      "Accuracy for 2 class is 0.03980099502487562 %\n",
      "Number of predicted class tags for 2 class in total 201: \n",
      " pred\n",
      "1       130\n",
      "5        31\n",
      "4        21\n",
      "3        11\n",
      "2         8\n",
      "Name: count, dtype: int64 \n",
      "Accuracy for 3 class is 0.030837004405286344 %\n",
      "Number of predicted class tags for 3 class in total 227: \n",
      " pred\n",
      "1       103\n",
      "5        63\n",
      "4        36\n",
      "2        18\n",
      "3         7\n",
      "Name: count, dtype: int64 \n"
     ]
    }
   ],
   "source": [
    "for class_name in df_test_longRNN['pred'].value_counts().index:\n",
    "    false_tags, g_a, total = get_accuracy(df_test_longRNN, class_name)\n",
    "    print(f'Accuracy for {class_name} class is {g_a} %')\n",
    "    if g_a <= 0.4:\n",
    "        print(f'Number of predicted class tags for {class_name} class in total {total}: \\n {false_tags} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**disbalanced classes is a real problem. I guess if this was a real task to work with this dataset with given instruments I would try to classify each small class (2, 3, 4) separately from all the others together**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "218/218 [==============================] - 33s 136ms/step - loss: 0.8758 - categorical_accuracy: 0.7238 - val_loss: 0.7025 - val_categorical_accuracy: 0.7503\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 28s 130ms/step - loss: 0.6657 - categorical_accuracy: 0.7726 - val_loss: 0.6667 - val_categorical_accuracy: 0.7594\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 28s 128ms/step - loss: 0.5893 - categorical_accuracy: 0.7915 - val_loss: 0.6820 - val_categorical_accuracy: 0.7613\n"
     ]
    }
   ],
   "source": [
    "model_LSTM = Sequential()\n",
    "\n",
    "model_LSTM.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model_LSTM.add(Masking(mask_value=0.0))\n",
    "model_LSTM.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model_LSTM.add(Dense(64, activation='relu'))\n",
    "model_LSTM.add(Dropout(0.5))\n",
    "model_LSTM.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_LSTM.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model_LSTM.fit(X_train, y_train_categ,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 2s 22ms/step - loss: 0.6930 - categorical_accuracy: 0.7601\n",
      "\n",
      "\n",
      "Test score: [0.692980170249939, 0.7601161599159241]\n"
     ]
    }
   ],
   "source": [
    "score = model_LSTM.evaluate(X_test, y_test_categ, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 2s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "results_LSTM = model_LSTM.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LSTM_preds = get_classes_df(results_LSTM, y_test.values, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 5 class is 0.9520153550863724 %\n",
      "Accuracy for 1 class is 0.7392086330935251 %\n",
      "Accuracy for 4 class is 0.07865168539325842 %\n",
      "Number of predicted class tags for 4 class: \n",
      " pred\n",
      "5       390\n",
      "1       101\n",
      "4        42\n",
      "3         1\n",
      "Name: count, dtype: int64 from total 534\n",
      "Accuracy for 3 class is 0.004405286343612335 %\n",
      "Number of predicted class tags for 3 class: \n",
      " pred\n",
      "1       125\n",
      "5        75\n",
      "4        25\n",
      "2         1\n",
      "3         1\n",
      "Name: count, dtype: int64 from total 227\n",
      "Accuracy for 2 class is 0 %\n",
      "Number of predicted class tags for 2 class: \n",
      " pred\n",
      "1       144\n",
      "5        42\n",
      "4        15\n",
      "Name: count, dtype: int64 from total 201\n"
     ]
    }
   ],
   "source": [
    "for class_name in df_LSTM_preds['pred'].value_counts().index:\n",
    "    false_tags, g_a, total = get_accuracy(df_LSTM_preds, class_name)\n",
    "    print(f'Accuracy for {class_name} class is {g_a} %')\n",
    "    if g_a <= 0.4:\n",
    "        print(f'Number of predicted class tags for {class_name} class: \\n {false_tags} from total {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "218/218 [==============================] - 27s 109ms/step - loss: 0.8302 - categorical_accuracy: 0.7303 - val_loss: 0.6969 - val_categorical_accuracy: 0.7548\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 23s 107ms/step - loss: 0.6382 - categorical_accuracy: 0.7795 - val_loss: 0.6764 - val_categorical_accuracy: 0.7600\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 23s 107ms/step - loss: 0.5547 - categorical_accuracy: 0.8008 - val_loss: 0.6988 - val_categorical_accuracy: 0.7490\n"
     ]
    }
   ],
   "source": [
    "model_GRU = Sequential()\n",
    "\n",
    "model_GRU.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model_GRU.add(Masking(mask_value=0.0))\n",
    "model_GRU.add(GRU(64, recurrent_dropout=0.2))\n",
    "model_GRU.add(Dense(64, activation='relu'))\n",
    "model_GRU.add(Dropout(0.5))\n",
    "model_GRU.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_GRU.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "history = model_GRU.fit(X_train, y_train_categ,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 2s 19ms/step - loss: 0.6978 - categorical_accuracy: 0.7576\n",
      "\n",
      "\n",
      "Test score: [0.6978428363800049, 0.7575992345809937]\n"
     ]
    }
   ],
   "source": [
    "score = model_GRU.evaluate(X_test, y_test_categ, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Test score after 3 epochs*   \n",
    "Test score: [0.7368313670158386, 0.7589545249938965]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 2s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "results_GRU = model_GRU.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GRU_preds = get_classes_df(results_GRU, y_test.values, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 5 class is 0.9366602687140115 %\n",
      "Accuracy for 1 class is 0.6888489208633094 %\n",
      "Accuracy for 4 class is 0.12734082397003746 %\n",
      "Number of predicted class tags for 4 class: \n",
      " pred\n",
      "5       340\n",
      "1        87\n",
      "4        68\n",
      "3        39\n",
      "Name: count, dtype: int64 from total 534\n",
      "Accuracy for 3 class is 0.1894273127753304 %\n",
      "Number of predicted class tags for 3 class: \n",
      " pred\n",
      "1       85\n",
      "5       54\n",
      "3       43\n",
      "4       41\n",
      "2        4\n",
      "Name: count, dtype: int64 from total 227\n",
      "Accuracy for 2 class is 0.014925373134328358 %\n",
      "Number of predicted class tags for 2 class: \n",
      " pred\n",
      "1       120\n",
      "5        31\n",
      "4        28\n",
      "3        19\n",
      "2         3\n",
      "Name: count, dtype: int64 from total 201\n"
     ]
    }
   ],
   "source": [
    "for class_name in df_GRU_preds['pred'].value_counts().index:\n",
    "    false_tags, g_a, total = get_accuracy(df_GRU_preds, class_name)\n",
    "    print(f'Accuracy for {class_name} class is {g_a} %')\n",
    "    if g_a <= 0.4:\n",
    "        print(f'Number of predicted class tags for {class_name} class: \\n {false_tags} from total {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After 3 epochs (early_stop = 'validation loss') with batch size 100**   \n",
    "Accuracy for 5 class is 0.9540704070407041 %   \n",
    "Accuracy for 1 class is 0.7403314917127072 %   \n",
    "Accuracy for 4 class is 0.09404990403071017 %   \n",
    "Number of predicted class tags for 4 class:    \n",
    " pred   \n",
    "5       357   \n",
    "1       115   \n",
    "4        49   \n",
    "Name: count, dtype: int64   \n",
    "**Classes 2 and 3 have 0% accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
